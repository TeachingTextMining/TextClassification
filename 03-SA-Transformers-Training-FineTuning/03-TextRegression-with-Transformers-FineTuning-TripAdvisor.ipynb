{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"private_outputs":true,"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9pOlP10M0DBB"},"source":["## Regresión sobre textos utilizando Transformers. Entrenando nuestro propio modelo\n","\n","\n","La regresión a partir de textos consiste en, dado un texto, asignarle un valor numérico continuo en un intervalo dado.\n","\n","En la actividad exploraremos cómo utilizar la librería [Transformers](https://huggingface.co/transformers/) para construir este modelo y entrenarlo para analizar reviews de [TripAdvisor](https://www.tripadvisor.com/) en el rango [1..5]\n","\n","Puede consultar el tutorial sobre [Fine-tunning de modelos](https://huggingface.co/transformers/custom_datasets.html#seq-imdb) en la web del proyecto  Transformers.\n","\n","**Instrucciones:**\n","\n","- siga las indicaciones y comentarios en cada apartado.\n","\n","\n","**Después de esta actividad nos habremos familiarizado con:**\n","\n","- la arquitectura y re-entrenamiento de un modelo para hacer regresión sobre textos basado en Transformers.\n","\n","- aspectos importantes a tener en cuenta como el formato de los datos para entrenar y realizar nuevas predicciones.\n","\n","**Requerimientos**\n","- tensorflow==2.15.0\n","- transformers==4.38.0\n","\n","\n","**Note que:** en dependencia del entorno de ejecución, puede ser necesario instalar manualmente alguno de estos paquetes.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"e3XEbmh7WL96"},"source":["<a name=\"sec:setup\"></a>\n","### Instalación de librerías e importación de dependencias.\n","\n","Para comenzar, es preciso instalar las dependencias, realizar los imports necesarios y definir algunas funciones auxiliares.\n","\n","Ejecute las siguientes casillas prestando atención a las instrucciones adicionales en los comentarios."]},{"cell_type":"code","metadata":{"id":"jmn-i8APWMjm"},"source":["# instalar librerías. Esta casilla es últil por ejemplo si se ejecuta el cuaderno en Google Colab\n","# Note que existen otras dependencias como tensorflow, etc. que en este caso se encontrarían ya instaladas\n","%%capture\n","#!pip install transformers==4.26.0 tensorflow==2.11 pandas==1.3.5 plotly==5.5.0 scikit-learn==1.0.0\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J0pI1gnw0DBF"},"source":["# reset environment\n","#%reset -f\n","\n","# para establecer caminos al guardar y leer archivos\n","import os\n","\n","# para cargar datos y realizar pre-procesamiento básico\n","import pandas as pd\n","from collections import Counter\n","from sklearn import preprocessing\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","# para evaluar los modelos\n","from sklearn.model_selection import train_test_split\n","# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay # clasificación -> métricas para regresión\n","from sklearn.metrics import mean_absolute_error # regresión -> métricas para regresión\n","\n","from sklearn.utils.multiclass import unique_labels\n","\n","#  para construir gráficas y realizar análisis exploratorio de los datos\n","import plotly.graph_objects as go\n","import plotly.figure_factory as ff\n","import plotly.express as px\n","from tqdm import tqdm\n","\n","# para guardar el modelo\n","import pickle\n","import tensorflow as tf\n","from transformers.modeling_tf_utils import keras\n","\n","# algoritmos de clasificación, tokenizadores, etc.\n","from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification, DistilBertConfig, TextClassificationPipeline\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L3G3KQUyXSUg"},"source":["# función auxiliar para obtener tensores de entrada al modelo a partir del texto\n","def get_model_inputs(cfg, data):\n","    # obtener ids y máscaras para el conjunto de entrenamiento\n","    # no es necesario convertir a tensores porque la salida del tokenizador se encuentra en este formato,\n","    encodings = cfg['tokenizer'](data, truncation=True, padding='max_length', max_length=cfg['max_length'], return_tensors=cfg['framework'])\n","\n","    # formatear los datos (tensores) de entrada de acuerdo con las opciones permitidas por TensorFlow\n","    # los nombres de las capas de Input creadas al construir el modelo ('input_ids', 'attention_mask', 'tfidf')\n","    # son utilizados como llaves en los diccionarios que representan las entradas al modelo\n","    inputs = {'input_ids': encodings['input_ids'],\n","            'attention_mask': encodings['attention_mask']\n","            }\n","    return inputs\n","\n","# función auxiliar para realizar predicciones con el modelo\n","def predict_model(model, cfg, data, pref='m'):\n","  \"\"\"\n","  data: list of the text to predict\n","  pref: identificador para las columnas (labels_[pref], scores_[pref]_[class 1], etc.)\n","  \"\"\"\n","  res = {}\n","  inputs = get_model_inputs(cfg, data)\n","  scores = model.predict(inputs)['logits']  # la salida de este modelo es TFSequenceClassifierOutput, debe tomarse el valor asociado a la llave 'logits'\n","\n","  # empaquetar scores dentro de un diccionario que contiene labels, scores clase 1, scores clase 2, .... El nombre de la clase se normaliza a lowercase\n","  if cfg['num_labels']==1: # si es clasificación binaria, este modelo devuelve solo 1 score por instancia\n","    res = {f'scores_{pref}': scores[:,0]}\n","  else:\n","    res = {f'scores_{pref}_{cls.lower()}': score for cls, score in zip(cfg['label_binarizer'].classes_, [col for col in scores.T])}\n","\n","  # añadir datos relativos a la predicción\n","  #labels = cfg['label_binarizer'].inverse_transform(scores) # clasificación -> realizar transformación inversa para obtener etiquetas\n","  labels = res[f'scores_{pref}'] # regresión -> no se requiere transformación inversa, el propio score se toma como predición\n","\n","  res[f'labels_{pref}'] = labels\n","\n","\n","  # convertir a dataframe ordenando las columnas primero el label y luego los scores por clase, las clases ordenadas alfabeticamente\n","  res = pd.DataFrame(res, columns=sorted(list(res.keys())))\n","  return res\n","\n","\n","# función auxiliar que evalúa los resultados de una clasificación\n","def evaluate_model_classification(y_true, y_pred, y_score=None, pos_label='positive'):\n","  print('==== Sumario de la clasificación ==== ')\n","  print(classification_report(y_true, y_pred))\n","\n","  print('Accuracy -> {:.2%}\\n'.format(accuracy_score(y_true, y_pred)))\n","\n","  # graficar matriz de confusión\n","  display_labels = sorted(unique_labels(y_true, y_pred), reverse=True)\n","  cm = confusion_matrix(y_true, y_pred, labels=display_labels)\n","\n","  z = cm[::-1]\n","  x = display_labels\n","  y =  x[::-1].copy()\n","  z_text = [[str(y) for y in x] for x in z]\n","\n","  fig_cm = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Viridis')\n","\n","  fig_cm.update_layout(\n","      height=400, width=400,\n","      showlegend=True,\n","      margin={'t':150, 'l':0},\n","      title={'text' : 'Matriz de Confusión', 'x':0.5, 'y':0.95, 'xanchor': 'center'},\n","      xaxis = {'title_text':'Valor Real', 'tickangle':45, 'side':'top'},\n","      yaxis = {'title_text':'Valor Predicho', 'tickmode':'linear'},\n","  )\n","  fig_cm.show()\n","\n","\n","  # curva roc (definido para clasificación binaria)\n","  fig_roc = None\n","  if y_score is not None:\n","    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=pos_label)\n","    fig_roc = px.area(\n","        x=fpr, y=tpr,\n","        title = f'Curva ROC (AUC={auc(fpr, tpr):.4f})',\n","        labels=dict(x='Ratio Falsos Positivos', y='Ratio Verdaderos Positivos'),\n","        width=400, height=400\n","    )\n","    fig_roc.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n","\n","    fig_roc.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","    fig_roc.update_xaxes(constrain='domain')\n","\n","    fig_roc.show()\n","\n","\n","def evaluate_model_regression(y_true, y_pred):\n","  print('Mean Absolute Error -> {:.2%}\\n'.format(mean_absolute_error(y_true, y_pred)))\n","\n","  figure_label_font_size = 12\n","  figure_annotation_fontsize = 10\n","  figure_height = 400\n","  figure_width = 800\n","  colorscale='reds'\n","  xtick_angle = 0\n","\n","  fig  = go.Figure()\n","  fig.add_trace(go.Scatter(x=y_true, y=y_pred, mode='markers'))\n","\n","  fig.update_layout(\n","    height=figure_height,\n","    width=figure_width,\n","    title={'text': 'Expected (x) vs Predicted (y) by Instance',\n","            'x':0.5, 'y':0.9, 'xanchor': 'center', 'yanchor': 'top',\n","            'font':{'size':figure_label_font_size},\n","          },\n","    showlegend=False,\n","    xaxis = {'title_text':'',\n","            'tickfont':{'size':figure_label_font_size*0.8},\n","            'titlefont':{'size':figure_label_font_size*0.8},\n","            'constrain':'domain',\n","            'tickmode':'auto',\n","            },\n","\n","    yaxis = {'title_text':'Predicted',\n","            'tickfont':{'size':figure_label_font_size*0.8},\n","            'titlefont':{'size':figure_label_font_size*0.8},\n","            'tickmode':'auto',\n","            'scaleanchor':'x',\n","            'scaleratio':1\n","            },\n","  )\n","  fig.show()\n","\n","\n","def load_data_tripadvisor(path:str):\n","    '''\n","    Funcion que procesa la base de datos a partir de la ruta en que se encuentra\n","    '''\n","    df = pd.read_csv(path, sep='\\t', index_col=0, names=['text', 'score'])\n","    df['Phrase'] = df['text'].str.split('_PROS_Liked_—_').str.get(0)\n","    df.rename(columns={'score':'Sentiment'}, inplace=True)\n","    return df.loc[:,['Phrase', 'Sentiment']]\n","\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"60mgkkJJJTGi"},"source":["### Carga de datos y análisis exploratorio\n","\n","El primer paso consiste en obtener los datos relacionados con nuestra tarea dejándolos en el formato adecuado.  Existen diferentes opciones, entre estas:\n","\n","- montar nuestra partición de Google Drive y leer un fichero desde esta.\n","\n","- leer los datos desde un fichero en una carpeta local.\n","\n","- leer los datos directamente de un URL.\n","\n","En este caso, se cargará un dataframe con la la siguiente estructura:\n","\n","| Phrase | Sentiment|\n","| ------ | ------ |\n","| This movie is really not all that bad...    | positive |\n","\n","\n","Ejecute la siguiente casilla para leer los datos.\n","\n"]},{"cell_type":"code","metadata":{"id":"JcOrYqNEkQei"},"source":["# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\n","#from google.colab import drive\n","#drive.mount('/content/drive')\n","#path = '/content/drive/MyDrive/Datos/ejercicio_tripadvisor.csv'\n","\n","# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n","#path = './sample_data/ejercicio_tripadvisor.csv'\n","\n","# descomente la siguiente línea para leer datos desde un URL\n","path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/03-SA-Transformers-Training-FineTuning/sample_data/ejercicio_tripadvisor.csv'\n","\n","# leer los datos\n","data = load_data_tripadvisor(path)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bYMSHHzykpiu"},"source":["Una vez leídos los datos, ejecute la siguiente casilla para construir una gráfica que muestra la distribución de clases en el corpus."]},{"cell_type":"code","metadata":{"id":"FdWJKv97YVbY"},"source":["text_col = 'Phrase'  # columna del dataframe que contiene el texto (depende del formato de los datos)\n","class_col = 'Sentiment'  # columna del dataframe que contiene la clase (depende del formato de los datos)\n","\n","# obtener algunas estadísticas sobre los datos\n","categories = sorted(data[class_col].unique(), reverse=False)\n","hist= Counter(data[class_col])\n","print(f'Total de instancias -> {data.shape[0]}')\n","print(f'Distribución de clases -> {{item[0]:round(item[1]/len(data[class_col]), 3) for item in sorted(hist.items(), key=lambda x: x[0])}}')\n","\n","print(f'Categorías -> {categories}')\n","print(f'Comentario de ejemplo -> {data[text_col][0]}')\n","print(f'Categoría del comentario -> {data[class_col][0]}')\n","\n","fig = go.Figure(layout=go.Layout(height=400, width=600))\n","fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in categories]))\n","fig.show()\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SA75he6UYgSL"},"source":["Finalmente, ejecute la siguiente casilla para crear los conjuntos de entrenamiento y validación que se utilizarán para entrenar y validar los modelos."]},{"cell_type":"code","metadata":{"id":"iRH4fhKrYg49"},"source":["# obtener conjuntos de entrenamiento (90%) y validación (10%)\n","seed = 0  # fijar random_state para reproducibilidad\n","train, val = train_test_split(data, test_size=.1, stratify=data[class_col], random_state=seed)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fuKfnywyV86e"},"source":["### Implementación y configuración del modelo\n","\n","Como hemos visto, la arquitectura del modelo consta de:\n","\n","- un extractor de rasgos con los que se describirá el texto. En nuestro caso, se utilizará una versión pre-entrenada de [DistilBERT](https://huggingface.co/transformers/model_doc/distilbert.html).\n","\n","- un clasificador que aprenderá a partir de un conjunto de ejemplos donde cada texto se representa a partir de los rasgos. En la actividad, el clasificador será una red neuronal.\n","\n","En la actividad, aprovecharemos una implementación de esta arquitectura incluida en Transformers mediante la clase [TFDistilBertForSequenceClassification](https://huggingface.co/transformers/model_doc/distilbert.html#tfdistilbertforsequenceclassification).\n","\n","Es decir, partiremos de un modelo pre-entrenado en datos diferentes a los nuestros (transfer-learning) realizando algunas iteraciones adicionales para ajustarlo a nuestro problema en particular (fine-tuning).\n","\n","Una ventaja de este enfoque es que, tanto el extractor como el clasificador se entrenarán conjuntamente para modelar nuestro problema.\n","\n","\n","**Notar que:**\n","\n","- en un problema de clasificación multiclases la última capa densa del clasificador debe tener tantas neuronas como posibles categorías contemple el problema. No obstante, en un problema de clasificación binaria, es recomendable tener una sola neurona. Ver *num_labels* en la configuración de DistilBERT.\n","\n","- los modelos que implementa Transformers funcionan como modelos [Keras](https://www.tensorflow.org/guide/keras?hl=es) por lo que al utilizarlos debe cuidarse que las entradas tengan el número y formato adecuado. En este caso, deben suministrarse tensores correspondientes al texto tokenizado y las respectivas attention masks.\n","\n","Ejecute las siguientes casillas prestando atención a los comentarios incluidos junto al código.\n"]},{"cell_type":"code","metadata":{"id":"11NFa2reJ9fc"},"source":["# configuraciones\n","cfg = {}  # diccionario para agrupar configuraciones y variables para su posterior uso\n","cfg['framework'] = 'tf'  # TensorFlow como framework (por cuestiones del formato en los datos)\n","cfg['max_length'] = 512  # máxima longitud de secuencia recomendada por DistilBERT\n","cfg['transformer_model_name'] = 'distilbert-base-uncased'\n","cfg['num_labels'] = 1  # clasificación -> 1 para clasificación binaria, o número de clases para clasificación multiclase n>2\n","cfg['num_labels'] = 1 # regresión -> siempre 1 a menos que se desee predecir un vector (caso no cubierto por la arquitectura)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"83jAjf5lKVL3"},"source":["#### Configuración del modelo"]},{"cell_type":"code","metadata":{"id":"veyHWjwn0DBM"},"source":["# configuraciones\n","config = DistilBertConfig(num_labels=cfg['num_labels'], seq_classif_dropout=0.5)\n","\n","# cargar el modelo pre-entrenado disponible en Transformers\n","model = TFDistilBertForSequenceClassification.from_pretrained(cfg['transformer_model_name'], config=config)\n","\n","# finalizar configuración del modelo\n","# se sugiere revisar documentación para más detalles sobre los diferentes hiper-parámetros\n","optimizer = keras.optimizers.Adam(learning_rate=5e-5)\n","\n","# definir función loss. Debe cuidarse que sea coherente con la salida esperada del modelo (vector de num_labels elementos)\n","# y el formato de los ejemplos (vector one-hot de num_labels componentes para codificar las categorías)\n","# loss = tf.keras.losses.BinaryCrossentropy(from_logits=True) # clasificación -> BinaryCrossEntropy para 2 clases o CategoricalCrossEntropy para >= clases\n","loss = keras.losses.MeanAbsoluteError() # regresión -> métrica apropiada para regresión\n","\n","# compilar el modelo, indicando otras métricas que se desee monitorear.\n","#metrics = ['binary_accuracy'] # clasificación -> métricas para clasificación, ej. binary_accuracy, categorical_accuracy\n","metrics = [keras.metrics.MeanAbsoluteError()] # regresión -> métricas para clasificación, ej. 'mae'\n","\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","\n","# imprimir sumario del modelo\n","model.summary()\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zIXGmNO4YujW"},"source":["### Pre-procesamiento de los datos\n","\n","Antes de entrenar, debemos pre-procesar los datos. Esto dependerá de la tarea en particular, en este caso, comprende:\n","\n","- tokenizar para obtener los ids y las máscaras. Debe tener en cuenta que el tokenizador debe ser compatible con el modelo a utilizar, DistilBERT en este caso.\n","\n","- obtener los vectores one-hot correspondientes a las categorías.\n","\n","- convertir a tensores cuando sea necesario, pues este será el formato de entrada que se utilizará en el modelo. Los tensores representan una estructura multidimensional de Tensorflow para contener los datos.\n","\n","**Notar que:**\n","- es necesario codificar el valor correspondiente a la categoría de modo que pueda procesarse por la red neuronal. Podemos asignar valor *1* a la categoría *positive* y *0* a la *negative*.  En un problema de clasificación multiclases, podemos realizar la codificación mediante un vector one-hot. En la actividad utilizaremos [LabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) de [scikit-learn](https://scikit-learn.org/stable/).\n","\n","Ejecute las siguiente casillas prestando atención a los comentarios explicativos."]},{"cell_type":"markdown","metadata":{"id":"Zr5cOi6aKztL"},"source":["#### Instanciar tokenizador, etc."]},{"cell_type":"code","metadata":{"id":"_9sWr5OxK0ET"},"source":["# cargar el tokenizador, disponible en Transformers\n","cfg['tokenizer'] = DistilBertTokenizer.from_pretrained(cfg['transformer_model_name'] )\n","\n","# instanciar y entrenar LabelBinarizer\n","#cfg['label_binarizer'] = preprocessing.LabelBinarizer() # clasificación -> convierte categorías a one-hot\n","                                                          # regresión -> no es necesario\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BZDtSJp3N5ys"},"source":["#### Pre-procesamiento"]},{"cell_type":"code","metadata":{"id":"pNN4mqo6YusN"},"source":["# entrenar LabelBinarizer\n","#cfg['label_binarizer'].fit(train[class_col]) # clasificación -> entrenar el encoder\n","                                              # regresión -> no es necesario\n","\n","# guardar LabelBinarizer para su uso posterior (decodificar las predicciones de nuevos datos)\n","#with open('label_binarizer_reviews.pkl', 'wb') as f:  # clasificación -> guardar\n","#    pickle.dump(cfg['label_binarizer'], f)\n","                                                       # regresión -> el encoder no estará definido\n","\n","\n","# obtener codificación one-hot\n","#train_blabels = cfg['label_binarizer'].transform(train[class_col]) # clasificación ->\n","#val_blabes = cfg['label_binarizer'].transform(val[class_col])\n","train_blabels = train[class_col] # regresión -> no es necesario transformar\n","val_blabes = val[class_col]\n","\n","# obtener tensores correspondientes\n","#train_blabels_t = tf.convert_to_tensor(train_blabels, dtype='int32') # clasificación -> tensores como int\n","#val_blabels_t = tf.convert_to_tensor(val_blabes, dtype='int32')\n","\n","train_blabels_t = tf.convert_to_tensor(train_blabels, dtype='float32') # regresióm -> tensores como float\n","val_blabels_t = tf.convert_to_tensor(val_blabes, dtype='float32')\n","\n","# obtener diccionarios representando las entradas del modelo\n","train_inputs = get_model_inputs(cfg, train[text_col].to_list())\n","val_inputs = get_model_inputs(cfg, val[text_col].to_list())\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x9L3WbPKZ5JA"},"source":["### Entrenamiento del modelo\n","\n","Por último, es necesario entrenar el modelo.\n","\n","**Notar que:**\n"," - la ejecución puede tomar un tiempo considerable (horas) o fallar por falta de memoria en dependencia del hardware y parámetros como el *batch_size*.\n","\n","- es recomendable guardar checkpoints del modelo luego de varias iteraciones. En este caso, se guardarán en carpeta con nombres tipo \"distilbert-reviews-epochs-[epoch_from]-[epoch_to]\", por ejemplo, \"distilbert-reviews-epochs-[003]-[003]\"."]},{"cell_type":"code","metadata":{"id":"6_zb7ESg0DBW"},"source":["# configuraciones\n","cfg['checkpoints_dir'] = 'checkpoints'  # directorio donde se guardarán los checkpoints al entrenar el modelo\n","cfg['model_name'] = 'distilbert-reviews'  # identificador al guardar los checkpoints\n","cfg['trained_model_name'] = os.path.join(cfg['checkpoints_dir'], cfg['model_name'])\n","\n","epochs_max = 1\n","epochs_to_save = 1 # si epochs_max % epochs_to_save !=0 podrían realizarse iteraciones extras\n","batch_size = 16\n","\n","# ciclo de entrenamiento y guardar checkpoints\n","for epoch_current in range(0, epochs_max, epochs_to_save):\n","    epoch_from = epoch_current +1\n","    epoch_to = epoch_current + epochs_to_save\n","    print(f'Training model, epochs {epoch_from} - {epoch_to}')\n","\n","    # entrenar el modelo. Opcionalmente, se puede suministrar datos de validación => validation_data=(val_inputs,val_blabels_t )\n","    model.fit(train_inputs, y=train_blabels_t, initial_epoch=epoch_current, epochs=epoch_to, batch_size=batch_size, validation_data=(val_inputs,val_blabels_t))\n","\n","    model.save_pretrained(cfg['trained_model_name'] + f'-epochs-{epoch_from:03d}-{epoch_to:03d}', )\n","    cfg['tokenizer'].save_pretrained(cfg['trained_model_name'] + f'-epochs-{epoch_from:03d}-{epoch_to:03d}')\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_gtuFJqtgUPi"},"source":["### Evaluación del modelo\n","Luego de entrenado el modelo, podemos evaluar su desempeño en los conjuntos de entrenamiento y validación.\n","\n","Ejecute la siguiente casilla para evaluar el modelo en el conjunto de entrenamiento."]},{"cell_type":"code","metadata":{"id":"S9iV_FnmgWJ6"},"source":["# predecir los datos de entrenamiento\n","data = train\n","true_labels = data[class_col]\n","\n","m_pred = predict_model(model, cfg, data[text_col].to_list(), pref='m')\n","\n","evaluate_model_regression(true_labels, m_pred['labels_m'])\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l99UlRtBw2cC"},"source":["Ejecute la siguiente casilla para evaluar el modelo en el conjunto de validación. Compare los resultados."]},{"cell_type":"code","metadata":{"id":"gcglNudkw2Rb"},"source":["# predecir los datos de validación\n","data = val\n","true_labels = data[class_col]\n","\n","m_pred = predict_model(model, cfg, data[text_col].to_list(), pref='m')\n","\n","evaluate_model_regression(true_labels, m_pred['labels_m'])\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mNP5324-t1G2"},"source":["## Predicción de nuevos datos\n","\n","Una vez entrenado el modelo, podemos evaluar su rendimiento en datos no utilizados durante el aprendizaje o emplearlo para predecir nuevas instancias. En cualquier caso, se debe cuidar realizar los pasos de pre-procesamiento necesarios según el caso. En el ejemplo, utilizaremos la porción de prueba preparada inicialmente.\n","\n","**Notar que**:\n","-  se cargará el modelo previamente entrenado, estableciendo las configuraciones pertinentes.\n","\n","- se debe decodificar la salida del modelo para obtener la correspondiente categoría utilizando el mismo codificador.\n","\n","- si disponemos de un modelo guardado, podremos ejecutar directamente esta parte del cuaderno. Sin embargo, será necesario al menos ejecutar previamente la sección [**Instalación de librerías...**](#sec:setup)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U4tGrVseaod7"},"source":["### Cargar otros elementos necesarios\n","\n","Antes de predecir nuevos datos, también es preciso cargar otros elementos necesarios como el tokenizador, el codificador para las etiquetas, etc.\n","\n","Ejecute la siguiente casilla."]},{"cell_type":"code","metadata":{"id":"1GuR0t96apOT"},"source":["# configuraciones\n","text_col = 'Phrase'  # columna del dataframe que contiene el texto (depende del formato de los datos)\n","class_col = 'Sentiment'  # columna del dataframe que contiene la clase (depende del formato de los datos)\n","\n","cfg = {}  # diccionario para agrupar configuraciones y variables para su posterior uso\n","cfg['framework'] = 'tf'  # TensorFlow como framework (por cuestiones del formato en los datos)\n","cfg['max_length'] = 512  # máxima longitud de secuencia recomendada por DistilBERT\n","cfg['transformer_model_name'] = 'distilbert-base-uncased'\n","cfg['num_labels'] = 1  # ver descripción de la sección \"Implementación y configuración del modelo\"\n","\n","cfg['checkpoints_dir'] = 'checkpoints'\n","cfg['model_name'] = 'distilbert-reviews-epochs-001-001'\n","cfg['trained_model_name'] = os.path.join(cfg['checkpoints_dir'], cfg['model_name'])\n","\n","# cargar el tokenizador (desde la carpeta del checkpoint)\n","cfg['tokenizer'] = DistilBertTokenizer.from_pretrained(cfg['trained_model_name'])\n","\n","# cargar el codificador one-hot utilizado para codificar los datos de entrenamiento\n","# es necesario para realizar la transformación inversa de la salida de la red y conocer el número de categorías\n","#with open('label_binarizer_reviews.pkl', 'rb') as f:\n","#    cfg['label_binarizer'] = pickle.load(f)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yAHxDO8RaQcG"},"source":["### Instanciar modelo pre-entrenado\n","\n","Para predecir nuevas instancias es preciso cargar el modelo previamente entrenado. Esto dependerá del formato en el que se exportó el modelo, pero en general se requieren dos elementos: la estructura del modelo y los pesos.\n","\n","Ejecute la siguiente casilla para cargar el modelo."]},{"cell_type":"code","metadata":{"id":"kraUymSvaQkE"},"source":["config = DistilBertConfig(num_labels=cfg['num_labels'])\n","\n","# cargar modelo entrenado para evaluarlo o predecir nuevos datos\n","model = TFDistilBertForSequenceClassification.from_pretrained(cfg['trained_model_name'], config=config)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BQ2zco-6a3zM"},"source":["### Predecir nuevos datos\n","\n","Con el modelo y el tokenizador cargados, es posible utilizarlo para analizar nuevos datos.\n","\n","Ejecute las siguientes casillas para:\n","\n","(a) categorizar un texto de muestra.\n","\n","(b) cargar nuevos datos, categorizarlos y mostrar algunas estadísticas sobre el corpus."]},{"cell_type":"code","metadata":{"id":"hJBXkDsza4PB"},"source":["# ejemplo de texto a clasificar, # lista [texto 1, text 2, ..., texto n]\n","text = ['Brian De Palma\\'s undeniable virtuosity can\\'t really camouflage the fact that his plot here is a thinly disguised\\\n","        \\\"Psycho\\\" carbon copy, but he does provide a genuinely terrifying climax. His \"Blow Out\", made the next year, was an improvement.']\n","\n","m_pred = predict_model(model, cfg, text, pref='m')\n","\n","pred_labels = m_pred['labels_m'].values[0]\n","pred_proba = m_pred['scores_m'].values[0]\n","\n","print(f'La sentimiento de la frase es -> {pred_labels}')\n","\n","print('Done!')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zrzsPZ_ucy2l"},"source":["También podemos predecir nuevos datos cargados desde un fichero.\n","\n","Ejecute la siguiente casilla, descomentando las instrucciones necesarias según sea el caso."]},{"cell_type":"code","metadata":{"id":"l1eKMQjncygu"},"source":["# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\n","#from google.colab import drive\n","#drive.mount('/content/drive')\n","#path = '/content/drive/MyDrive/Datos/ejercicio_tripadvisor.csv'\n","\n","# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n","#path = './sample_data/ejercicio_tripadvisor.csv'\n","\n","# descomente la siguiente línea para leer datos desde un URL\n","path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/03-SA-Transformers-Training-FineTuning/sample_data/ejercicio_tripadvisor.csv'\n","\n","# leer los datos\n","new_data = load_data_tripadvisor(path)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"luJu-v8idK6s"},"source":["Ejecute la siguiente casilla para predecir los datos y mostrar algunas estadísticas sobre el análisis realizado."]},{"cell_type":"code","metadata":{"id":"GO19VjnHP9s0"},"source":["# predecir los datos de prueba\n","m_pred = predict_model(model, cfg, new_data[text_col].to_list(), pref='m')\n","pred_labels = m_pred['labels_m']\n","\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"imdxBpwbAfuL"},"execution_count":null,"outputs":[]}]}