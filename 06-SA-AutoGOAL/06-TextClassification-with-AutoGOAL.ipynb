{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06-TextClassification-with-AutoGOAL.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sRscuhsfcWJr"},"source":["<a href=\"https://colab.research.google.com/github/TeachingTextMining/TextClassification/blob/main/06-SA-AutoGOAL/06_TextClassification_with_AutoGOAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"76GWp3TtCltu"},"source":["## Clasificación de textos utilizando AutoML\n","\n","\n","La clasificación de textos consiste en, dado un texto, asignarle una entre varias categorías. Algunos ejemplos de esta tarea son:\n","\n","- dado un tweet, categorizar su connotación como positiva, negativa o neutra.\n","- dado un post de Facebook, clasificarlo como portador de un lenguaje ofensivo o no.  \n","\n","En la actividad exploraremos cómo utilizar soluciones *out of the box* para esta tarea incluidas en la librería [AutoGOAL](https://github.com/autogoal/autogoal) y su aplicación para clasificar reviews de [IMDB](https://www.imdb.com/) sobre películas en las categorías \\[$positive$, $negative$\\]. \n","\n","\n","\n","**Instrucciones:**\n","\n","- siga las indicaciones y comentarios en cada apartado.\n","\n","\n","**Después de esta actividad nos habremos familiarizado con:**\n","- cómo modelar un problema de clasificación con AutoGOAL\n","- cómo utilizar AutoGOAL para buscar automáticamente un *pipeline* para clasificación de textos.\n","- utilizar este *pipeline* para clasificar nuevos textos.\n","\n","**Requerimientos**\n","- python 3.6.12 - 3.8\n","- tensorflow==2.3.0\n","- autogoal==0.4.4\n","- pandas==1.1.5\n","- plotly==4.13.0\n","- tqdm==4.56.0\n"]},{"cell_type":"markdown","metadata":{"id":"qs8-IuHAWhw2"},"source":["<a name=\"sec:setup\"></a>\n","### Instalación de librerías e importación de dependencias.\n","\n","Para comenzar, es preciso instalar e incluir las librerías necesarias. En este caso, el entorno de Colab incluye las necesarias.\n","\n","Ejecute la siguiente casilla prestando atención a las explicaciones dadas en los comentarios."]},{"cell_type":"code","metadata":{"id":"Lxub5L7JWiIl"},"source":["# instalar librerías. Esta casilla es últil por ejemplo si se ejecuta el cuaderno en Google Colab\n","# Note que existen otras dependencias como tensorflow, etc. que en este caso se encontrarían ya instaladas\n","%%capture\n","!pip install autogoal[contrib]==0.4.4\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ga7lVYFMCltv"},"source":["# reset environment\n","%reset -f\n","\n","#  para construir gráficas y realizar análisis exploratorio de los datos\n","import plotly.graph_objects as go\n","import plotly.figure_factory as ff\n","import plotly.express as px\n","\n","# para cargar datos y realizar pre-procesamiento básico\n","import pandas as pd\n","from collections import Counter\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","# para evaluar los modelos \n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, f1_score\n","from sklearn.utils.multiclass import unique_labels\n","\n","# para configurar AutoGOAL\n","from autogoal.ml import AutoML\n","from autogoal.search import (Logger, PESearch, ConsoleLogger, ProgressLogger, MemoryLogger)\n","from autogoal.kb import MatrixContinuousDense, VectorCategorical, Supervised\n","from autogoal.contrib import find_classes\n","\n","# para guardar el modelo\n","import pickle\n","import datetime\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zvCAcoPfntwB"},"source":["#### Definición de funciones y variables necesarias para el pre-procesamiento de datos\n","\n","Antes de definir el pipeline definiremos algunas variables útiles como el listado de stop words y funciones para cargar los datos, entrenar el modelo etc."]},{"cell_type":"code","metadata":{"id":"4jvtD8EWoA-p"},"source":["# función auxiliar para realizar predicciones con el modelo\n","def predict_model(model, cfg, data, pref='m'):\n","  \"\"\"\n","  data: list of the text to predict\n","  pref: identificador para las columnas (labels_[pref], scores_[pref]_[class 1], etc.)\n","  \"\"\"\n","  res = {}\n","  scores = None\n","\n","  data_tfidf = cfg['vectorizer'].transform(data)\n","  data_tfidf = data_tfidf.todense()\n","  labels = model.predict(data_tfidf)\n","\n","  if hasattr(model, 'predict_proba'):\n","    scores = model.predict_proba(data_tfidf)\n","  \n","    # empaquetar scores dentro de un diccionario que contiene labels, scores clase 1, scores clase 2, .... El nombre de la clase se normaliza a lowercase\n","    res = {f'scores_{pref}_{cls.lower()}':score for cls, score in zip(model.classes_, [col for col in scores.T])}\n","\n","  # añadir datos relativos a la predicción\n","  res[f'labels_{pref}'] = cfg['label_encoder'].inverse_transform(labels)\n","\n","  # convertir a dataframe ordenando las columnas primero el label y luego los scores por clase, las clases ordenadas alfabeticamente.\n","  res = pd.DataFrame(res, columns=sorted(list(res.keys())))\n","\n","  return res\n","\n","\n","# función auxiliar que evalúa los resultados de una clasificación\n","def evaluate_model(y_true, y_pred, y_score=None, pos_label='positive'):\n","  \"\"\"\n","  data: list of the text to predict\n","  pref: identificador para las columnas (labels_[pref], scores_[pref]_[class 1], etc.)\n","  \"\"\"\n","  print('==== Sumario de la clasificación ==== ')\n","  print(classification_report(y_true, y_pred))\n","\n","  print('Accuracy -> {:.2%}\\n'.format(accuracy_score(y_true, y_pred)))\n","\n","  # graficar matriz de confusión\n","  display_labels = sorted(unique_labels(y_true, y_pred), reverse=True)\n","  cm = confusion_matrix(y_true, y_pred, labels=display_labels)\n","\n","  z = cm[::-1]\n","  x = display_labels\n","  y =  x[::-1].copy()\n","  z_text = [[str(y) for y in x] for x in z]\n","\n","  fig_cm = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Viridis')\n","\n","  fig_cm.update_layout(\n","      height=400, width=400,\n","      showlegend=True,\n","      margin={'t':150, 'l':0},\n","      title={'text' : 'Matriz de Confusión', 'x':0.5, 'xanchor': 'center'},\n","      xaxis = {'title_text':'Valor Real', 'tickangle':45, 'side':'top'},\n","      yaxis = {'title_text':'Valor Predicho', 'tickmode':'linear'},\n","  )\n","  fig_cm.show()\n","\n","\n","  # curva roc (definido para clasificación binaria)\n","  fig_roc = None\n","  if y_score is not None:\n","    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=pos_label)\n","    fig_roc = px.area(\n","        x=fpr, y=tpr,\n","        title={'text' : f'Curva ROC (AUC={auc(fpr, tpr):.4f})', 'x':0.5, 'xanchor': 'center'},\n","        labels=dict(x='Ratio Falsos Positivos', y='Ratio Verdaderos Positivos'),\n","        width=400, height=400\n","    )\n","    fig_roc.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n","\n","    fig_roc.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","    fig_roc.update_xaxes(constrain='domain')\n","    \n","    fig_roc.show()\n","\n","\n","# custom logger\n","# - imprime y guarda el mejor pipeline cada vez que se encuentre una nueva solución candidad\n","# - imprime pipelines cuya evaluación falló\n","class CustomLogger(Logger):\n","    def __init__(self, classifier, save_model=True, check_folder=\".\"):\n","        self.save_model = save_model\n","        self.check_folder = check_folder\n","        self.classifier = classifier\n","\n","    def error(self, e: Exception, solution):\n","        if e and solution:\n","            with open(\"reviews_errors.log\", \"a\") as fp:\n","                fp.write(f\"solution={repr(solution)}\\nerror={repr(e)}\\n\\n\")\n","\n","    def update_best(self, new_best, new_fn, *args):\n","        pipecode = datetime.datetime.now(datetime.timezone.utc).strftime(\"reviews--%Y-%m-%d--%H-%M-%S--{0}\".format(hex(id(new_best))))\n","        with open(\"reviews_update_best.log\", \"a\") as fp:\n","            fp.write(f\"\\n{pipecode}\\nsolution={repr(new_best)}\\nfitness={new_fn}\\n\\n\")\n","\n","        if(self.save_model):\n","            fp = open('{1}.pkl'.format(self.check_folder,pipecode), 'wb')\n","            new_best.sampler_.replay().save(fp)\n","            pickle.Pickler(fp).dump((self.classifier.input, self.classifier.output))\n","            fp.close()\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Me0P5d8PoHFo"},"source":["<a name=\"sec:load-data\"></a>\n","### Carga de datos y análisis exploratorio\n","\n","Antes de entrenar el pipeline, es necesario cargar los datos. Existen diferentes opciones, entre estas:\n","\n","- montar nuestra partición de Google Drive y leer un fichero desde esta.\n","\n","- leer los datos desde un fichero en una carpeta local.\n","\n","- leer los datos directamente de un URL.\n","\n","Ejecute la siguiente casilla prestando atención a las instrucciones adicionales en los comentarios.\n"]},{"cell_type":"code","metadata":{"id":"Tg6pvcsVoHZ4"},"source":["# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\n","#from google.colab import drive\n","#drive.mount('/content/drive')\n","#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\n","\n","# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n","#path = './sample_data/ejemplo_review_train.csv'\n","\n","# descomente la siguiente línea para leer datos desde un URL\n","path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/06-SA-AutoGOAL/sample_data/ejemplo_review_train.csv'\n","\n","# leer los datos\n","data = pd.read_csv(path, sep=',')\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"suEnoVDuoMvZ"},"source":["Una vez leídos los datos, ejecute la siguiente casilla para construir una gráfica que muestra la distribución de clases en el corpus. "]},{"cell_type":"code","metadata":{"id":"UQG6uQTNoNIY"},"source":["text_col = 'Phrase'  # columna del dataframe que contiene el texto (depende del formato de los datos)\n","class_col = 'Sentiment'  # columna del dataframe que contiene la clase (depende del formato de los datos)\n","\n","# obtener algunas estadísticas sobre los datos\n","categories = sorted(data[class_col].unique(), reverse=False)\n","hist= Counter(data[class_col]) \n","print(f'Total de instancias -> {data.shape[0]}')\n","print(f'Distribución de clases -> {{item[0]:round(item[1]/len(data[class_col]), 3) for item in sorted(hist.items(), key=lambda x: x[0])}}')\n","\n","print(f'Categorías -> {categories}')\n","print(f'Comentario de ejemplo -> {data[text_col][0]}')\n","print(f'Categoría del comentario -> {data[class_col][0]}')\n","\n","fig = go.Figure(layout=go.Layout(height=400, width=600))\n","fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in categories]))\n","fig.show()\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_-_EGWESoRsA"},"source":["Finalmente, ejecute la siguiente casilla para crear los conjuntos de entrenamiento y validación que se utilizarán para entrenar y validar los modelos."]},{"cell_type":"code","metadata":{"id":"NLK_nyK1oSAP"},"source":["# obtener conjuntos de entrenamiento (90%) y validación (10%)\n","seed = 0  # fijar random_state para reproducibilidad\n","train, val = train_test_split(data, test_size=.1, stratify=data[class_col], random_state=seed)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xQB9gdvrokzJ"},"source":["### Implementación y configuración del modelo\n","\n","Con AutoGOAL podemos configurar el modelo facilmente pues solo necesitamos instanciar la clase AutomML. Lo más importante es elegir los tipos adecuados para datos de entrada y salida en nuestro modelo y la métrica de evaluación. En este caso:\n","\n","- entrada (input), una tupla de:\n","    - MatrixContinuousDense -> una fila por instancia y una columna por variable.\n","    - Supervised[VectorCategorical]) -> indica se trata de aprendizaje supervisado.\n","\n","- salida (output): VectorCategorical -> el elemento *i* representa la categoría asociada a la instancia *i*.\n","\n","Ejecute la siguiente casilla prestando atención a los comentarios adicionales."]},{"cell_type":"code","metadata":{"id":"uZoQNW4PClt4"},"source":["# configuraciones\n","cfg = {}\n","cfg['iterations'] = 1 # cantidad de iteraciones a realizar\n","cfg['popsize'] = 50  # tamaño de la población\n","cfg['search_timeout'] = 120  # tiempo máximo de búsqueda en segundos\n","cfg['evaluation_timeout'] = 60  # tiempo máximo que empleará evaluando un pipeline en segundos\n","cfg['memory'] = 20  # cantidad máxima de memoria a utilizar\n","cfg['score_metric'] = f1_score  # métrica de evaluación\n","\n","search_kwargs=dict(\n","    pop_size=cfg['popsize'],\n","    search_timeout=cfg['search_timeout'],\n","    evaluation_timeout=cfg['evaluation_timeout'],\n","    memory_limit=cfg['memory'] * 1024 ** 3,\n",")\n","\n","model = AutoML(\n","    input=(MatrixContinuousDense, Supervised[VectorCategorical]),  # tipo datos de entrada\n","    output=VectorCategorical,  # tipo datos de salida\n","    \n","    score_metric=cfg['score_metric'],\n","    search_algorithm=PESearch,  # algoritmo de búsqueda\n","    registry=None,  # para incluir clases adicionales \n","    \n","    search_iterations=cfg['iterations'],\n","    \n","    include_filter=\".*\",  # indica qué módulos pueden incluirse en los pipelines evaluados\n","    exclude_filter=None,  # indica módulos a excluir de los pipelines evaluados\n","    \n","    validation_split=0.3,  # porción de los datos de entrenamiento que AutoGOAL tomará para evaluar cada pipeline\n","    cross_validation_steps=3,  # cantidad de particiones en la crossvalidación\n","    cross_validation=\"mean\",  # tipo de agregación para los valores de la métrica en cada partición de la crossvalidación (promedio, mediana, etc.)\n","    \n","    random_state=None,  # semilla para el generador de números aleatorios\n","    errors=\"warn\",  # tratamiento ante errores\n","    **search_kwargs\n",")\n","\n","# configurar loggers\n","loggers = [ProgressLogger(), ConsoleLogger(), MemoryLogger(), CustomLogger(model, save_model=True, check_folder=\".\")]\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rRRPI2CzOCOo"},"source":["<a name=\"sec:pre-proc\"></a>\n","### Pre-procesamiento de los datos\n","\n","Antes de entrenar, debemos pre-procesar los datos. Esto dependerá de la tarea en particular, en este caso, comprende:\n","\n","- obtener vectores tf-idf correspondientes a cada ejemplo.\n","\n","- codificar las categorías como números utilizando [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) de [scikit-learn](https://scikit-learn.org/stable/). \n","\n","**Notar que:**\n","\n","- en dependencia de su implementación del extractor o del número de clases, deberá re-implementar esta sección para codificar los datos adecuadamente.\n","\n","Ejecute la siguiente casilla prestando atención a los comentarios explicativos."]},{"cell_type":"markdown","metadata":{"id":"4yoryqRsO8ik"},"source":["#### Instanciar tf-idf vectorizer, etc."]},{"cell_type":"code","metadata":{"id":"iNb1SPTMClt7"},"source":["# instanciar TfidfVectorizer\n","cfg['vectorizer'] = TfidfVectorizer(stop_words='english', max_features=10000)\n","\n","# instanciar LabelEncoder\n","cfg['label_encoder'] = LabelEncoder()\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tuOwIoYjPLC8"},"source":["#### Pre-procesamiento"]},{"cell_type":"code","metadata":{"id":"4nlsy-9IClt-"},"source":["# entrenar TfidfVectorizer\n","cfg['vectorizer'].fit(train[text_col].to_list())\n","\n","# guardar TfidfVectorizer entrenado para su posterior uso (codificar nuevos datos).\n","with open('vectorizer_reviews.pkl', 'wb') as f:\n","    pickle.dump(cfg['vectorizer'], f)\n","\n","# entrenar LabelEncoder\n","cfg['label_encoder'].fit(train[class_col])\n","\n","# guardar LabelEncoder entrenado para su posterior uso (codificar nuevos datos).\n","with open('label_encoder_reviews.pkl', 'wb') as f:\n","    pickle.dump(cfg['label_encoder'], f)\n","\n","# obtener representaciones tf-idf correspondientes\n","train_tfidf = cfg['vectorizer'].transform(train[text_col])\n","val_tfidf = cfg['vectorizer'].transform(val[text_col])\n","\n","# formatear adecuadamente dado que la salida de TfidfVectorizer es de tipo scipy.sparse.csr.csr_matrix.\n","# no que AutoGOAL puede procesar scipy.sparse.csr.csr_matrix al entrenar, pero no necesariamente al predecir \n","# por lo que se sugiere formatear siempre\n","train_tfidf = train_tfidf.todense() \n","val_tfidf = val_tfidf.todense()\n","\n","# codificar labels\n","train_labels = cfg['label_encoder'].transform(train[class_col])\n","val_labels = cfg['label_encoder'].transform(val[class_col])\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5rn4Poq2R4UX"},"source":["### Entrenamiento del modelo\n","\n","Por último es necesario \"entrenar el modelo\", que en este caso significa iniciar la búsqueda.\n","\n"]},{"cell_type":"code","metadata":{"id":"-J2Rf7dvXh7m"},"source":["model.fit(train_tfidf, train_labels, logger=loggers)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DLh4KHHgX_bw"},"source":["Finalmente, guardamos el modelo, este contendrá el mejor pipeline encontrado."]},{"cell_type":"code","metadata":{"id":"XBnxcf0WSj4h"},"source":["with open('model_reviews.pkl', 'wb') as f:\n","    model.save(f)\n","    \n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n_9A1ZkyfCq4"},"source":["### Evaluación del modelo\n","Luego de entrenado el modelo, podemos evaluar su desempeño en los conjuntos de entrenamiento y validación.\n","\n","Ejecute la siguiente casilla para evaluar el modelo en el conjunto de entrenamiento."]},{"cell_type":"code","metadata":{"id":"Uh_wgiOfXOWZ"},"source":["# predecir y evaluar el modelo en el conjunto de entrenamiento\n","print('==== Evaluación conjunto de entrenamiento ====')\n","data = train\n","true_labels = data[class_col]\n","\n","m_pred = predict_model(model, cfg, data[text_col].to_list(), pref='m')\n","\n","# el nombre de los campos dependerá de pref al llamar a predic_model y las clases. Ver comentarios en la definición de la función\n","evaluate_model(true_labels, m_pred['labels_m'])  \n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g2hZlaFL7omz"},"source":["Ejecute la siguiente casilla para evaluar el modelo en el conjunto de validación. Compare los resultados."]},{"cell_type":"code","metadata":{"id":"O1vinOtO7o-h"},"source":["# predecir y evaluar el modelo en el conjunto de validación\n","print('==== Evaluación conjunto de validacióm ====')\n","data = val\n","true_labels = data[class_col]\n","\n","m_pred = predict_model(model, cfg, data[text_col].to_list(), pref='m')\n","\n","# el nombre de los campos dependerá de pref al llamar a predic_model y las clases. Ver comentarios en la definición de la función\n","evaluate_model(true_labels, m_pred['labels_m'])  \n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4-jAoCZGPqCj"},"source":["## Predicción de nuevos datos\n","\n","Una vez entrenado el modelo, podemos evaluar su rendimiento en datos no utilizados durante el entrenamiento o emplearlo para predecir nuevas instancias. En cualquier caso, se debe cuidar realizar los pasos de pre-procesamiento necesarios según el caso. En el ejemplo, utilizaremos la porción de prueba preparada inicialmente.\n","\n","**Notar que**:\n","-  se cargará el modelo previamente entrenado y guardado, estableciendo las configuraciones pertinentes.\n","\n","- si disponemos de un modelo guardado, podremos ejecutar directamente esta parte del cuaderno. Sin embargo, será necesario al menos ejecutar previamente la sección [Instalación de librerías...](#sec:setup)\n"]},{"cell_type":"markdown","metadata":{"id":"-ism0f1cbbH_"},"source":["### Cargar otros elementos necesarios \n","\n","Antes de predecir nuevos datos, también es preciso cargar otros elementos necesarios como el codificador para las etiquetas, etc.\n","\n","Ejecute la siguiente casilla."]},{"cell_type":"code","metadata":{"id":"6DriOyJkbbd5"},"source":["# configuraciones\n","text_col = 'Phrase'  # columna del dataframe que contiene el texto (depende del formato de los datos)\n","class_col = 'Sentiment'  # columna del dataframe que contiene la clase (depende del formato de los datos)\n","\n","cfg = {}  # diccionario para agrupar configuraciones y variables para su posterior uso\n","\n","# cargar el LabelEncoder\n","with open('label_encoder_reviews.pkl', 'rb') as f:\n","    cfg['label_encoder'] = pickle.load(f)\n","\n","# cargar TfidfVectorizer\n","with open('vectorizer_reviews.pkl', 'rb') as f:\n","    cfg['vectorizer'] = pickle.load(f)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I4Fmkq3BPyvf"},"source":["### Instanciar modelo pre-entrenado\n","\n","Para predecir nuevas instancias es preciso cargar el modelo previamente entrenado.\n","\n","Ejecute la siguiente casilla para cargar el pipeline."]},{"cell_type":"code","metadata":{"id":"lcFQIegh7p-a"},"source":["# cargar mejor pipeline\n","model = None\n","with open('model_reviews.pkl', 'rb') as f:\n","    model = AutoML.load(f)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3H4me-h3eJLh"},"source":["### Predecir nuevos datos\n","\n","Con el modelo cargado, es posible utilizarlo para analizar nuevos datos. \n","\n","Ejecute las siguientes casillas para:\n","\n","(a) categorizar un texto de muestra.\n","\n","(b) cargar nuevos datos, categorizarlos y mostrar algunas estadísticas sobre el corpus."]},{"cell_type":"code","metadata":{"id":"njoBIOJ-d-yg"},"source":["# ejemplo de texto a clasificar en formato [text 1, text 2, ..., text n]\n","text = ['Brian De Palma\\'s undeniable virtuosity can\\'t really camouflage the fact that his plot here is a thinly disguised\\\n","        \\\"Psycho\\\" carbon copy, but he does provide a genuinely terrifying climax. His \"Blow Out\", made the next year, was an improvement.']\n","\n","# predecir los nuevos datos.\n","m_pred = predict_model(model, cfg, text, pref='m')\n","\n","# el nombre de los campos dependerá de pref al llamar a predic_model y las clases. Ver comentarios en la definición de la función\n","pred_labels = m_pred['labels_m'].values[0]\n","\n","print(f'La categoría del review es -> {pred_labels}')\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"soc1PQnEeZon"},"source":["También podemos predecir nuevos datos cargados desde un fichero. \n","\n","Ejecute la siguiente casilla, descomentando las instrucciones necesarias según sea el caso."]},{"cell_type":"code","metadata":{"id":"Sz8QkhPeeTlX"},"source":["# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\n","#from google.colab import drive\n","#drive.mount('/content/drive')\n","#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\n","\n","# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n","#path = './sample_data/ejemplo_review_train.csv'\n","\n","# descomente la siguiente línea para leer datos desde un URL\n","path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/01-SA-Pipeline/sample_data/ejemplo_review_test.csv'\n","\n","# leer los datos\n","new_data = pd.read_csv(path, sep=',')\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4UTCvP3QecrH"},"source":["Ejecute la siguiente celda para predecir los datos y mostrar algunas estadísticas sobre el análisis realizado."]},{"cell_type":"code","metadata":{"id":"9VGbyGdRebLH"},"source":["# predecir los datos de prueba\n","m_pred = predict_model(model, cfg, new_data[text_col].to_list(), pref='m')\n","pred_labels = m_pred['labels_m']\n","\n","# obtener algunas estadísticas sobre la predicción en el conjunto de pruebas\n","categories = sorted(pred_labels.unique(), reverse=False)\n","hist = Counter(pred_labels.values) \n","\n","fig = go.Figure(layout=go.Layout(height=400, width=600))\n","fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in categories]))\n","fig.show()\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZfWPYGwyefkH"},"source":[""],"execution_count":null,"outputs":[]}]}